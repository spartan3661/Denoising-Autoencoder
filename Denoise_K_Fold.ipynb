{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as F\n",
    "from math import log10\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "#from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.amp import GradScaler, autocast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder_conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.encoder_bn1 = nn.BatchNorm2d(64)\n",
    "        self.encoder_relu1 = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.encoder_pool1 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "        self.encoder_bn2 = nn.BatchNorm2d(128)\n",
    "        self.encoder_relu2 = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.encoder_pool2 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.encoder_conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1)\n",
    "        self.encoder_bn3 = nn.BatchNorm2d(256)\n",
    "        self.encoder_relu3 = nn.LeakyReLU(negative_slope=0.2)\n",
    "        self.encoder_pool3 = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        self.decoder_conv1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder_bn1 = nn.BatchNorm2d(128)\n",
    "        self.decoder_relu1 = nn.ReLU()\n",
    "        \n",
    "        self.decoder_conv2 = nn.ConvTranspose2d(128 + 128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder_bn2 = nn.BatchNorm2d(64)\n",
    "        self.decoder_relu2 = nn.ReLU()\n",
    "        \n",
    "        self.decoder_conv3 = nn.ConvTranspose2d(64 + 64, 3, kernel_size=2, stride=2)\n",
    "        self.decoder_sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder_pool1(self.encoder_relu1(self.encoder_bn1(self.encoder_conv1(x))))\n",
    "        x1 = self.dropout(x1)\n",
    "\n",
    "        x2 = self.encoder_pool2(self.encoder_relu2(self.encoder_bn2(self.encoder_conv2(x1))))\n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        x3 = self.encoder_pool3(self.encoder_relu3(self.encoder_bn3(self.encoder_conv3(x2))))\n",
    "        x3 = self.dropout(x3)\n",
    "        \n",
    "        x4 = self.decoder_relu1(self.decoder_bn1(self.decoder_conv1(x3)))\n",
    "\n",
    "        x4 = torch.cat((x4, x2), dim=1)\n",
    "        \n",
    "        x5 = self.decoder_relu2(self.decoder_bn2(self.decoder_conv2(x4)))\n",
    "\n",
    "        x5 = torch.cat((x5, x1), dim=1)\n",
    "\n",
    "        x6 = self.decoder_sigmoid(self.decoder_conv3(x5))\n",
    "\n",
    "        return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CLEAN_PATH = config[\"train_clean_dir\"]\n",
    "TRAIN_NOISY_PATH = config[\"train_noisy_dir\"]\n",
    "VALID_CLEAN_PATH = config[\"valid_clean_dir\"]\n",
    "VALID_NOISY_PATH = config[\"valid_noisy_dir\"]\n",
    "\n",
    "class CombinedNoisyCleanDataset(Dataset):\n",
    "    def __init__(self, clean_dirs, noisy_dirs, transform=None):\n",
    "        self.clean_dirs = clean_dirs\n",
    "        self.noisy_dirs = noisy_dirs\n",
    "        self.clean_images = []\n",
    "        self.noisy_images = []\n",
    "        self.transform = transform\n",
    "\n",
    "        for clean_dir, noisy_dir in zip(clean_dirs, noisy_dirs):\n",
    "            clean_imgs = os.listdir(clean_dir)\n",
    "            noisy_imgs = os.listdir(noisy_dir)\n",
    "            self.clean_images += [(clean_dir, img) for img in clean_imgs]\n",
    "            self.noisy_images += [(noisy_dir, img) for img in noisy_imgs]\n",
    "\n",
    "        assert len(self.clean_images) == len(self.noisy_images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clean_dir, clean_image_name = self.clean_images[idx]\n",
    "        noisy_dir, noisy_image_name = self.noisy_images[idx]\n",
    "\n",
    "        clean_image_path = os.path.join(clean_dir, clean_image_name)\n",
    "        noisy_image_path = os.path.join(noisy_dir, noisy_image_name)\n",
    "\n",
    "        clean_image = Image.open(clean_image_path).convert('RGB')\n",
    "        noisy_image = Image.open(noisy_image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            clean_image = self.transform(clean_image)\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "\n",
    "        return noisy_image, clean_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_splits = config[\"k_fold\"]\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "clean_dirs = [TRAIN_CLEAN_PATH, VALID_CLEAN_PATH]\n",
    "noisy_dirs = [TRAIN_NOISY_PATH, VALID_NOISY_PATH]\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(tuple(config[\"train_resize_shape\"])),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "combined_dataset = CombinedNoisyCleanDataset(clean_dirs, noisy_dirs, transform=transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold = 0\n",
    "for train_idx, val_idx in kf.split(range(len(combined_dataset))):\n",
    "    fold += 1\n",
    "    print(f\"Fold {fold}:\")\n",
    "\n",
    "    train_subset = Subset(combined_dataset, train_idx)\n",
    "    val_subset = Subset(combined_dataset, val_idx)\n",
    "\n",
    "    train_loader = DataLoader(train_subset, batch_size=config[\"denoise_model\"][\"batch_size\"], shuffle=True)\n",
    "    val_loader = DataLoader(val_subset, batch_size=config[\"denoise_model\"][\"batch_size\"], shuffle=False)\n",
    "\n",
    "    model = DenoisingAutoencoder()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=config[\"denoise_model\"][\"learning_rate\"], weight_decay=config[\"denoise_model\"][\"optimizer_weight_decay\"])\n",
    "    '''\n",
    "    scheduler = ReduceLROnPlateau(\n",
    "        optimizer, mode=config[\"denoise_model\"][\"scheduler\"][\"mode\"], \n",
    "        factor=config[\"denoise_model\"][\"scheduler\"][\"factor\"], \n",
    "        patience=config[\"denoise_model\"][\"scheduler\"][\"patience\"])\n",
    "    '''\n",
    "    scaler = torch.amp.GradScaler()\n",
    "\n",
    "    for epoch in range(config[\"denoise_model\"][\"epochs\"]):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        total_psnr = 0.0\n",
    "        total_ssim = 0.0\n",
    "        batch_idx = 0\n",
    "\n",
    "        with tqdm(total=len(train_loader), desc=f\"Training Fold {fold}, Epoch {epoch}\") as pbar:\n",
    "            for noisy_imgs, clean_imgs in train_loader:\n",
    "                batch_idx += 1\n",
    "                optimizer.zero_grad()\n",
    "                with autocast(device_type=\"cuda\", enabled=True):  \n",
    "                    outputs = model(noisy_imgs)\n",
    "                    mse_loss = F.mse_loss(outputs, clean_imgs)\n",
    "                    ssim_loss = 1 - ssim(outputs, clean_imgs, data_range=1.0, size_average=True)\n",
    "                    loss = config[\"denoise_model\"][\"mse_alpha\"] * mse_loss + config[\"denoise_model\"][\"ssim_beta\"] * ssim_loss\n",
    "                scaler.scale(loss).backward()\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "\n",
    "\n",
    "                running_loss += loss.item()\n",
    "                psnr = 10 * log10(1 / mse_loss.item())\n",
    "                total_psnr += psnr\n",
    "                total_ssim += (1 - ssim_loss.item())\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Batch': f\"{batch_idx}/{len(train_loader)}\",\n",
    "                    'MSE Loss': f\"{mse_loss.item():.6f}\",\n",
    "                    'SSIM Loss': f\"{ssim_loss.item():.6f}\",\n",
    "                    'Combined Loss': f\"{loss.item():.6f}\"\n",
    "                })\n",
    "                pbar.update(1)\n",
    "\n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        avg_psnr = total_psnr / len(train_loader)\n",
    "        avg_ssim = total_ssim / len(train_loader)\n",
    "        print(f\"Fold {fold}, Epoch {epoch}, Average Training Loss: {epoch_loss:.6f}, Average PSNR: {avg_psnr:.6f}, Average SSIM: {avg_ssim:.6f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    batch_idx = 0\n",
    "    with tqdm(total=len(val_loader), desc=f\"Validating Fold {fold}\") as pbar:\n",
    "        with torch.no_grad():\n",
    "            for noisy_imgs, clean_imgs in val_loader:\n",
    "                batch_idx += 1\n",
    "                outputs = model(noisy_imgs)\n",
    "                mse_loss = F.mse_loss(outputs, clean_imgs)\n",
    "                ssim_loss = 1 - ssim(outputs, clean_imgs, data_range=1.0, size_average=True)\n",
    "                loss = config[\"denoise_model\"][\"mse_alpha\"] * mse_loss + config[\"denoise_model\"][\"ssim_beta\"] * ssim_loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                psnr = 10 * log10(1 / mse_loss.item())\n",
    "                total_psnr += psnr\n",
    "                total_ssim += (1 - ssim_loss.item())\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Batch': f\"{batch_idx}/{len(val_loader)}\",\n",
    "                    'MSE Loss': f\"{mse_loss.item():.6f}\",\n",
    "                    'SSIM Loss': f\"{ssim_loss.item():.6f}\",\n",
    "                    'Combined Validation Loss': f\"{loss.item():.6f}\"\n",
    "                })\n",
    "                pbar.update(1)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_psnr = total_psnr / len(val_loader)\n",
    "    avg_val_ssim = total_ssim / len(val_loader)\n",
    "    print(f\"Validation Loss for Fold {fold}: {avg_val_loss:.6f}, Average PSNR: {avg_val_psnr:.6f}, Average SSIM: {avg_val_ssim:.6f}\\n\")\n",
    "\n",
    "    #scheduler.step(avg_val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')\n",
    "torch.save(model, \"./models/DenoiseAutoencoder.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
