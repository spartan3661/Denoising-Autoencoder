{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, Subset\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "from PIL import Image\n",
    "from pytorch_msssim import ssim\n",
    "import torch.nn.functional as F\n",
    "from math import log10\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "import json\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.amp import GradScaler, autocast\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.json', 'r') as config_file:\n",
    "    config = json.load(config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenoisingAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(DenoisingAutoencoder, self).__init__()\n",
    "        \n",
    "        self.encoder_conv1 = nn.Conv2d(3, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.encoder_bn1 = nn.BatchNorm2d(64)\n",
    "        self.encoder_relu1 = nn.LeakyReLU(negative_slope=0.2)\n",
    "        \n",
    "        self.encoder_conv2 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.encoder_bn2 = nn.BatchNorm2d(128)\n",
    "        self.encoder_relu2 = nn.LeakyReLU(negative_slope=0.2)\n",
    "        \n",
    "        self.encoder_conv3 = nn.Conv2d(128, 256, kernel_size=3, stride=2, padding=1)\n",
    "        self.encoder_bn3 = nn.BatchNorm2d(256)\n",
    "        self.encoder_relu3 = nn.LeakyReLU(negative_slope=0.2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "\n",
    "        self.channel_attention = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Conv2d(256, 256 // 16, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(256 // 16, 256, kernel_size=1),\n",
    "            nn.Sigmoid()\n",
    "\n",
    "        )\n",
    "\n",
    "        \n",
    "        self.decoder_conv1 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.decoder_bn1 = nn.BatchNorm2d(128)\n",
    "        self.decoder_relu1 = nn.ReLU()\n",
    "        \n",
    "        self.decoder_conv2 = nn.ConvTranspose2d(128 + 128, 64, kernel_size=2, stride=2)\n",
    "        self.decoder_bn2 = nn.BatchNorm2d(64)\n",
    "        self.decoder_relu2 = nn.ReLU()\n",
    "        \n",
    "        self.decoder_conv3 = nn.ConvTranspose2d(64 + 64, 3, kernel_size=2, stride=2)\n",
    "        self.decoder_sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.encoder_relu1(self.encoder_bn1(self.encoder_conv1(x)))\n",
    "        x1 = self.dropout(x1)\n",
    "\n",
    "        x2 = self.encoder_relu2(self.encoder_bn2(self.encoder_conv2(x1)))\n",
    "        x2 = self.dropout(x2)\n",
    "\n",
    "        x3 = self.encoder_relu3(self.encoder_bn3(self.encoder_conv3(x2)))\n",
    "        x3 = self.dropout(x3)\n",
    "        \n",
    "\n",
    "        attn = self.channel_attention(x3)\n",
    "        x3 = x3 * attn\n",
    "\n",
    "        x4 = self.decoder_relu1(self.decoder_bn1(self.decoder_conv1(x3)))\n",
    "\n",
    "        x4 = torch.cat((x4, x2), dim=1)\n",
    "        \n",
    "        x5 = self.decoder_relu2(self.decoder_bn2(self.decoder_conv2(x4)))\n",
    "\n",
    "        x5 = torch.cat((x5, x1), dim=1)\n",
    "\n",
    "        x6 = self.decoder_sigmoid(self.decoder_conv3(x5))\n",
    "\n",
    "        return x6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CLEAN_PATH = config[\"train_clean_dir\"]\n",
    "TRAIN_NOISY_PATH = config[\"train_noisy_dir\"]\n",
    "VALID_CLEAN_PATH = config[\"valid_clean_dir\"]\n",
    "VALID_NOISY_PATH = config[\"valid_noisy_dir\"]\n",
    "\n",
    "class NoisyCleanDataset(Dataset):\n",
    "    def __init__(self, clean_dir, noisy_dir, transform=None):\n",
    "        self.clean_dir = clean_dir\n",
    "        self.noisy_dir = noisy_dir\n",
    "        self.clean_images = os.listdir(self.clean_dir)\n",
    "        self.noisy_images = os.listdir(self.noisy_dir)\n",
    "        self.transform = transform\n",
    "\n",
    "        assert len(self.clean_images) == len(self.noisy_images)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.clean_images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clean_image_name = self.clean_images[idx]\n",
    "        noisy_image_name = self.noisy_images[idx]\n",
    "\n",
    "        clean_image_path = os.path.join(self.clean_dir, clean_image_name)\n",
    "        noisy_image_path = os.path.join(self.noisy_dir, noisy_image_name)\n",
    "\n",
    "        clean_image = Image.open(clean_image_path).convert('RGB')\n",
    "        noisy_image = Image.open(noisy_image_path).convert('RGB')\n",
    "\n",
    "        if self.transform:\n",
    "            clean_image = self.transform(clean_image)\n",
    "            noisy_image = self.transform(noisy_image)\n",
    "\n",
    "        return noisy_image, clean_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(tuple(config[\"train_resize_shape\"])),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = NoisyCleanDataset(TRAIN_CLEAN_PATH, TRAIN_NOISY_PATH, transform=transform)\n",
    "val_dataset = NoisyCleanDataset(VALID_CLEAN_PATH, VALID_NOISY_PATH, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=config[\"denoise_model\"][\"batch_size\"], shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=config[\"denoise_model\"][\"batch_size\"], shuffle=False)\n",
    "\n",
    "model = DenoisingAutoencoder()\n",
    "optimizer = optim.Adam(model.parameters(), lr=config[\"denoise_model\"][\"learning_rate\"], weight_decay=config[\"denoise_model\"][\"optimizer_weight_decay\"])\n",
    "\n",
    "\n",
    "\n",
    "scheduler = ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode=config[\"denoise_model\"][\"scheduler\"][\"mode\"],\n",
    "    factor=config[\"denoise_model\"][\"scheduler\"][\"factor\"],\n",
    "    patience=config[\"denoise_model\"][\"scheduler\"][\"patience\"]\n",
    ")\n",
    "\n",
    "scaler = torch.amp.GradScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_step = config[\"denoise_model\"][\"gradient_accumulation_steps\"]\n",
    "previous_avg_val_loss = 0\n",
    "for epoch in range(config[\"denoise_model\"][\"epochs\"]):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    batch_idx = 0\n",
    "    \n",
    "\n",
    "    with tqdm(total=len(train_loader), desc=f\"Training Epoch {epoch}\") as pbar:\n",
    "        for noisy_imgs, clean_imgs in train_loader:\n",
    "            batch_idx += 1\n",
    "            \n",
    "            with autocast(device_type=\"cuda\", enabled=True):  \n",
    "                outputs = model(noisy_imgs)\n",
    "                mse_loss = F.mse_loss(outputs, clean_imgs)\n",
    "                ssim_loss = 1 - ssim(outputs, clean_imgs, data_range=1.0, size_average=True)\n",
    "                loss = config[\"denoise_model\"][\"mse_alpha\"] * mse_loss + config[\"denoise_model\"][\"ssim_beta\"] * ssim_loss\n",
    "                \n",
    "                loss = loss / accumulation_step\n",
    "            \n",
    "            scaler.scale(loss).backward()\n",
    "\n",
    "            if (batch_idx % accumulation_step == 0) or (batch_idx == len(train_loader)):\n",
    "                scaler.step(optimizer)\n",
    "                scaler.update()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            running_loss += loss.item() * accumulation_step\n",
    "            psnr = 10 * log10(1 / mse_loss.item())\n",
    "            total_psnr += psnr\n",
    "            total_ssim += (1 - ssim_loss.item())\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'Batch': f\"{batch_idx}/{len(train_loader)}\",\n",
    "                'MSE Loss': f\"{mse_loss.item():.6f}\",\n",
    "                'SSIM Loss': f\"{ssim_loss.item():.6f}\",\n",
    "                'Combined Loss': f\"{loss.item() * accumulation_step:.6f}\"\n",
    "            })\n",
    "            pbar.update(1)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    avg_psnr = total_psnr / len(train_loader)\n",
    "    avg_ssim = total_ssim / len(train_loader)\n",
    "    print(f\"Epoch {epoch}, Average Training Loss: {epoch_loss:.6f}, Average PSNR: {avg_psnr:.6f}, Average SSIM: {avg_ssim:.6f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    total_psnr = 0.0\n",
    "    total_ssim = 0.0\n",
    "    batch_idx = 0\n",
    "    with tqdm(total=len(val_loader), desc=\"Validating\") as pbar:\n",
    "        with torch.no_grad():\n",
    "            for noisy_imgs, clean_imgs in val_loader:\n",
    "                batch_idx += 1\n",
    "                outputs = model(noisy_imgs)\n",
    "                mse_loss = F.mse_loss(outputs, clean_imgs)\n",
    "                ssim_loss = 1 - ssim(outputs, clean_imgs, data_range=1.0, size_average=True)\n",
    "                loss = config[\"denoise_model\"][\"mse_alpha\"] * mse_loss + config[\"denoise_model\"][\"ssim_beta\"] * ssim_loss\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                psnr = 10 * log10(1 / mse_loss.item())\n",
    "                total_psnr += psnr\n",
    "                total_ssim += (1 - ssim_loss.item())\n",
    "\n",
    "                pbar.set_postfix({\n",
    "                    'Batch': f\"{batch_idx}/{len(val_loader)}\",\n",
    "                    'MSE Loss': f\"{mse_loss.item():.6f}\",\n",
    "                    'SSIM Loss': f\"{ssim_loss.item():.6f}\",\n",
    "                    'Combined Validation Loss': f\"{loss.item():.6f}\"\n",
    "                })\n",
    "                pbar.update(1)\n",
    "\n",
    "    avg_val_loss = val_loss / len(val_loader)\n",
    "    avg_val_psnr = total_psnr / len(val_loader)\n",
    "    avg_val_ssim = total_ssim / len(val_loader)\n",
    "    scheduler.step(avg_val_loss)\n",
    "    print(f\"Validation Loss: {avg_val_loss:.6f}, Average PSNR: {avg_val_psnr:.6f}, Average SSIM: {avg_val_ssim:.6f}\\n\")\n",
    "\n",
    "    if avg_val_loss > previous_avg_val_loss:\n",
    "        torch.save(model, \"./models/DenoiseAutoencoderV4.pth\")\n",
    "        previous_avg_val_loss = avg_val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Done')\n",
    "torch.save(model, \"./models/DenoiseAutoencoderV4.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
